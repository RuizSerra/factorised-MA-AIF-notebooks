{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ\n",
    "\n",
    "Notebook where we answer some questions about the model that may arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling log preferences\n",
    "\n",
    "When computing the risk (observations) term in the EFE, $D_{KL}[q(\\bar o_j|u)||p^*(o_j)]$,\n",
    "we use the algebraic form $\\mathbf{\\bar o}_j (\\log \\mathbf{\\bar o}_j - \\log \\boldsymbol{\\mathsf{C}}^j)$\n",
    "(logs are always shifted by EPSILON to avoid numerical issues).\n",
    "Noting that, \n",
    "$$\n",
    "\\log \\boldsymbol{\\mathsf{C}}^j = \\log p^*(o_j) = \\mathbb{E}_{q(\\bar o_i=u_i, \\bar o_k)}[\\log p^*(o_i=u_i, o_j, o_k)]\n",
    "$$\n",
    "\n",
    "One might be concerned that we do not normalise or otherwise scale $\\log p^*(o_j)$ to be in the same \"range\" as $\\log q(\\bar o_j|u)$.\n",
    "\n",
    "The next cell shows that this is not necessary, as the relative KL divergence between the actions is invariant to scaling of the target distribution.\n",
    "The risk for each action is different if we scale the target distribution, but the **relative risk between actions is the same whether we rescale or not**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST, AS IS ------------------------\n",
      "q(o|u)\t\t[1.0, 0.0]\n",
      "log q(o|u)\t[0.0, -20.7232666015625]\n",
      "log p*(o)\t[-2.0964999198913574, 5.599999904632568]\n",
      "Risk\t\t2.0964999198913574\n",
      "exp(log p*(o)) = p(^o)\t[0.12288578599691391, 270.4263916015625]\n",
      "log p(^o)\t[-2.0964999198913574, 5.599999904632568]\n",
      "\n",
      "q(o|u)\t\t[0.0, 1.0]\n",
      "log q(o|u)\t[-20.7232666015625, 0.0]\n",
      "log p*(o)\t[-2.0964999198913574, 5.599999904632568]\n",
      "Risk\t\t-5.599999904632568\n",
      "exp(log p*(o)) = p(^o)\t[0.12288578599691391, 270.4263916015625]\n",
      "log p(^o)\t[-2.0964999198913574, 5.599999904632568]\n",
      "\n",
      "Delta risk\t-7.696499824523926\n",
      "\n",
      "SECOND, NORMALISED ------------------------\n",
      "q(o|u)\t\t[1.0, 0.0]\n",
      "log q(o|u)\t[0.0, -20.7232666015625]\n",
      "log p*(o)\t[-7.696951866149902, -0.00045435020001605153]\n",
      "Risk\t\t7.696951866149902\n",
      "exp(log p*(o)) = p(^o)\t[0.0004542095703072846, 0.9995457530021667]\n",
      "log p(^o)\t[-7.696949481964111, -0.00045435020001605153]\n",
      "\n",
      "q(o|u)\t\t[0.0, 1.0]\n",
      "log q(o|u)\t[-20.7232666015625, 0.0]\n",
      "log p*(o)\t[-7.696951866149902, -0.00045435020001605153]\n",
      "Risk\t\t0.00045435020001605153\n",
      "exp(log p*(o)) = p(^o)\t[0.0004542095703072846, 0.9995457530021667]\n",
      "log p(^o)\t[-7.696949481964111, -0.00045435020001605153]\n",
      "\n",
      "Delta risk\t-7.696497515949886\n",
      "\n",
      "THIRD VERSION, Exponentiate and Softmax ------------------------\n",
      "C_mod (after exp): [0.0004542095703072846, 0.9995457530021667]\n",
      "C_mod (after softmax): [0.26912006735801697, 0.7308799624443054]\n",
      "log_C_modality (after log): [-1.312597632408142, -0.31350603699684143]\n",
      "q(o|u)\t\t[1.0, 0.0]\n",
      "log q(o|u)\t[0.0, -20.7232666015625]\n",
      "log p*(o)\t[-1.312597632408142, -0.31350603699684143]\n",
      "Risk\t\t1.312597632408142\n",
      "exp(log p*(o)) = p(^o)\t[0.26912006735801697, 0.7308799624443054]\n",
      "log p(^o)\t[-1.312597632408142, -0.31350603699684143]\n",
      "\n",
      "q(o|u)\t\t[0.0, 1.0]\n",
      "log q(o|u)\t[-20.7232666015625, 0.0]\n",
      "log p*(o)\t[-1.312597632408142, -0.31350603699684143]\n",
      "Risk\t\t0.31350603699684143\n",
      "exp(log p*(o)) = p(^o)\t[0.26912006735801697, 0.7308799624443054]\n",
      "log p(^o)\t[-1.312597632408142, -0.31350603699684143]\n",
      "\n",
      "Delta risk\t-0.9990915954113007\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_actions = 2\n",
    "EPSILON = 1e-9\n",
    "log_C_modality = torch.tensor([-2.0965, 5.6])  # Assume at the current timestep the log C_modality is this\n",
    "\n",
    "def print_metrics(log_C_modality):\n",
    "    risk = []\n",
    "    for u_i in [0, 1]:\n",
    "        o_pred = torch.tensor([1.0 if i == u_i else 0.0 for i in range(num_actions)])\n",
    "        log_o_pred = torch.log(o_pred + EPSILON)\n",
    "        print('q(o|u)', o_pred.tolist(), sep='\\t\\t')\n",
    "        print('log q(o|u)', log_o_pred.tolist(), sep='\\t')\n",
    "        print('log p*(o)', log_C_modality.tolist(), sep='\\t')\n",
    "        risk.append((o_pred @ (log_o_pred - log_C_modality)).item())\n",
    "        print('Risk', risk[u_i], sep='\\t\\t')\n",
    "        \n",
    "        # Compute exp(log C_modality) and log p(^o)\n",
    "        exp_log_C_modality = torch.exp(log_C_modality)\n",
    "        print('exp(log p*(o)) = p(^o)', exp_log_C_modality.tolist(), sep='\\t')\n",
    "        \n",
    "        log_p_hat_o = torch.log(exp_log_C_modality + EPSILON)\n",
    "        print('log p(^o)', log_p_hat_o.tolist(), sep='\\t')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    print('Delta risk', risk[1] - risk[0], sep='\\t')\n",
    "\n",
    "\n",
    "print('FIRST, AS IS ------------------------')\n",
    "print_metrics(log_C_modality)\n",
    "\n",
    "print('\\nSECOND, NORMALISED ------------------------')\n",
    "C_mod = torch.softmax(log_C_modality, dim=0)\n",
    "log_C_modality = torch.log(C_mod + EPSILON)  # cf. LogSumExp\n",
    "print_metrics(log_C_modality)\n",
    "\n",
    "\n",
    "# THIRD VERSION: Exponential of log_C, then softmax, and then log if necessary\n",
    "print('\\nTHIRD VERSION, Exponentiate and Softmax ------------------------')\n",
    "C_mod = torch.exp(log_C_modality)  # Step 1: Exponentiate to get C from log_C\n",
    "print(\"C_mod (after exp):\", C_mod.tolist())\n",
    "\n",
    "C_mod = torch.softmax(C_mod, dim=0)  # Step 2: Apply softmax to C\n",
    "print(\"C_mod (after softmax):\", C_mod.tolist())\n",
    "\n",
    "log_C_modality = torch.log(C_mod + EPSILON)  # Step 3: Take the log of softmax'ed C\n",
    "print(\"log_C_modality (after log):\", log_C_modality.tolist())\n",
    "\n",
    "print_metrics(log_C_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1.],\n",
       "         [4., 2.]]),\n",
       " tensor([[0.2369, 0.0321],\n",
       "         [0.6439, 0.0871]]),\n",
       " tensor([[-1.4402, -3.4402],\n",
       "         [-0.4402, -2.4402]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from games import *\n",
    "\n",
    "log_C = prisoners_dilemma_2player\n",
    "\n",
    "#Format log_C into a legit probability distribution\n",
    "flattened_C = torch.softmax(log_C.flatten(), dim=0)\n",
    "C = flattened_C.view_as(log_C)\n",
    "log_C_new = torch.log(C)\n",
    "assert torch.isclose(\n",
    "        torch.exp(log_C_new).sum(), \n",
    "        torch.tensor(1.0), \n",
    "        atol=1e-6), (\n",
    "    \"The sum of exponentiated values of log C is not 1.\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(log_C)\n",
    "axs[0].set_title('log C')\n",
    "axs[1].imshow(C)\n",
    "axs[1].set_title('C')\n",
    "axs[2].imshow(log_C_new)\n",
    "axs[2].set_title('log C new')\n",
    "plt.show()\n",
    "\n",
    "log_C, C, log_C_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9820, 0.0180],\n",
      "         [0.0180, 0.9820]],\n",
      "\n",
      "        [[0.9820, 0.0180],\n",
      "         [0.0180, 0.9820]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(26.7926)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "## Scaffold\n",
    "num_actions = 2\n",
    "num_agents = 2\n",
    "EPSILON = torch.finfo().eps\n",
    "A_params = torch.stack([torch.eye(num_actions) for _ in range(num_agents)]) + EPSILON  # Identity observation model prior\n",
    "\n",
    "# A_params += 0.1\n",
    "A_params = torch.softmax(4*A_params, dim=2)\n",
    "print(A_params)\n",
    "A = A_params / A_params.sum(dim=1, keepdim=True)\n",
    "\n",
    "q_s_u = torch.tensor([\n",
    "    [0.43, 0.57],\n",
    "    [0.57, 0.43]\n",
    "])\n",
    "\n",
    "#############\n",
    "novelty = 0\n",
    "# Da Costa et al. (2020; Eq. D.17)\n",
    "W = 0.5 * (1/A_params - 1/A_params.sum(dim=1, keepdim=True))\n",
    "for factor_idx in range(num_agents):\n",
    "    s_pred = q_s_u[factor_idx]\n",
    "    novelty += torch.dot(\n",
    "        A[factor_idx] @ s_pred, \n",
    "        W[factor_idx] @ s_pred)\n",
    "novelty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0100, 1.0300],\n",
      "          [1.0300, 1.3100]],\n",
      "\n",
      "         [[1.0100, 1.0300],\n",
      "          [1.0300, 1.3100]]],\n",
      "\n",
      "\n",
      "        [[[1.3400, 1.0200],\n",
      "          [1.0200, 1.0000]],\n",
      "\n",
      "         [[1.3400, 1.0200],\n",
      "          [1.0200, 1.0000]]]])\n",
      "tensor([[[[0.2391, 0.2415],\n",
      "          [0.2415, 0.2778]],\n",
      "\n",
      "         [[0.2391, 0.2415],\n",
      "          [0.2415, 0.2778]]],\n",
      "\n",
      "\n",
      "        [[[0.2819, 0.2402],\n",
      "          [0.2402, 0.2378]],\n",
      "\n",
      "         [[0.2819, 0.2402],\n",
      "          [0.2402, 0.2378]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_agents = 2\n",
    "num_actions = 2\n",
    "\n",
    "# Scaffolding\n",
    "B_posterior_params = torch.tensor([\n",
    "    [[  # Factor i -------------\n",
    "        [1.01, 1.03],    # u = 0\n",
    "        [1.03, 1.35]],\n",
    "    [\n",
    "        [1.01, 1.03],    # u = 1\n",
    "        [1.03, 1.35]]],\n",
    "\n",
    "    [[  # Factor j -------------\n",
    "        [1.38, 1.02],    # u = 0\n",
    "        [1.02, 1.00]],\n",
    "    [\n",
    "        [1.38, 1.02],    # u = 1\n",
    "        [1.02, 1.00]]]\n",
    "])\n",
    "\n",
    "B_params = torch.tensor([[[[1.01, 1.03],\n",
    "          [1.03, 1.31]],\n",
    "\n",
    "         [[1.01, 1.03],\n",
    "          [1.03, 1.31]]],\n",
    "\n",
    "\n",
    "        [[[1.34, 1.02],\n",
    "          [1.02, 1.00]],\n",
    "\n",
    "         [[1.34, 1.02],\n",
    "          [1.02, 1.00]]]])\n",
    "\n",
    "print(B_params)\n",
    "B_reduced = F.softmax(0.5*B_params.view(num_agents, num_actions, -1), dim=-1).view_as(B_params)\n",
    "print(B_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004, -0.0004],\n",
       "        [-0.0004, -0.0004]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_prior = B_params / B_params.sum(dim=2, keepdim=True)\n",
    "B_posterior = B_posterior_params / B_posterior_params.sum(dim=2, keepdim=True)\n",
    "\n",
    "# Expected value (under B_posterior) of the ratio of the reduced to the prior\n",
    "torch.log(\n",
    "    torch.einsum(\n",
    "        'funk,funk->fu',\n",
    "        B_posterior,\n",
    "        B_reduced / B_prior\n",
    "        # B_prior / B_reduced\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9996)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B_reduced[0, 0].flatten() / B_prior[0, 0].flatten()) @ B_posterior[0, 0].flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesa-abm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
